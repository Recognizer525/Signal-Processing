\documentclass[11pt]{article}
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, left=2.5cm, right=1.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{animate} 
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{tikz}
\usepackage{comment}
\usepackage{animate} 
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{tikz}
\usepackage{comment}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{cancel}
\usepackage{mathtools}
\usepackage[most]{tcolorbox}
\usepackage[mathscr]{euscript}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
 
\newcommand{\Expect}{\mathbb{E}}
\newcommand{\Var}{\mathcal{D}}
\newcommand{\Cov}{\mathsf{cov}}
\newcommand{\Norm}{\mathcal{N}}
\newcommand{\NormComplex}{\mathcal{CN}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Int}{\mathbb{Z}}
\newcommand{\XSig}{\mathbf{x}}
\newcommand{\Ssig}{\mathbf{s}}
\newcommand{\Nsig}{\mathbf{n}}
\newcommand{\Rs}{\mathbf{R}_s}
\newcommand{\Rn}{\mathbf{R}_n}
\newcommand{\DK}{\mathbf{D}_{KL}}
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\Det}{Det}
\newcommand{\infdiv}{D_{KL}\infdivx}
\newcommand\Fontvi{\fontsize{8.2}{7.2}\selectfont}
\newcommand\Fontvia{\fontsize{9}{8}\selectfont}
\newcommand\Fontvib{\fontsize{10.8}{9.6}\selectfont}
\newcommand\Fontvic{\fontsize{8.0}{7.0}\selectfont}
\newcommand{\myitem}{\item[\checkmark]}
%\newcommand{\myitem}{\item[\squares]}

\begin{document}
\begin{center}
\fontsize{20}{23}\selectfont \color{red}{\textbf{ЕCМ-алгоритм, стохастическая модель сигнала}}
\end{center}
Введем некоторые условные обозначения:
\begin{itemize}
\item
$\theta$ --- вектор направлений прибытия сигнала (DoA);
\item
$\tau$ --- итерация ЕCМ-алгоритма, начальная оценка параметров $\theta$;
\item
$t$ --- момент времени (а заодно и номер кадра (snapshot));
\item
$L$ --- число датчиков;
\item
$M$ --- число источников (источники разделяют общую длину центральной волны $\chi$);
\item
$G$ --- число независимых кадров/снимков (snapshot), сделанных в разные моменты времени;
\item
$S$ --- набор сигналов (случайная величина), испускаемых источниками в моменты времени $t=\overline{1,G}$, $S_t$ соответствует сигналу в момент времени $t$, представляет собой матрицу размера $G \times M$;
\item
$s$ --- набор сигналов (реализация), испускаемых источниками в моменты времени $t=\overline{1,G}$, $s_t$ соответствует сигналу в момент времени $t$;
\item
$N$ --- набор шумов (случайная величина), связанных с датчиками в моменты времени $t=\overline{1,G}$, $N_t$ соответствует шуму в момент времени $t$, представляет собой матрицу размера $G \times L$;
\item
$n$ --- набор шумов (реализация), связанных с датчиками в моменты времени $t=\overline{1,G}$, $n_t$ соответствует шуму в момент времени $t$;
\item
$X$ --- набор сигналов (случайная величина), полученных датчиками в моменты времени $t=\overline{1,G}$, $X_t$ соответствует сигналу в момент времени $t$, представляет собой матрицу размера $G \times L$;
\item
$x$ --- набор сигналов (реализация), полученных датчиками в моменты времени $t=\overline{1,G}$, $x_t$ соответствует сигналу в момент времени $t$;
\item
$X_o$ --- наблюдаемая часть (случайная величина) $X$, $X_{o_t}$ соответствует сигналу в момент времени $t$; 
\item
$x_o$ --- наблюдаемая часть (реализация) $X$, $x_{o_t}$ соответствует сигналу в момент времени $t$;
\item
$X_m$ --- ненаблюдаемая часть (случайная величина) $X$, $X_{m_t}$ соответствует сигналу в момент времени $t$;
\item
$x_m$ --- ненаблюдаемая часть (реализация) $X$, $x_{m_t}$ соответствует сигналу в момент времени $t$;
\item
$\mathbf{O}_{D_1 \times D_2}$ --- нулевая матрица размера $D_1 \times D_2$;
\item
Полученный сигнал (итоговый сигнал, получаемый массивом датчиков):
\begin{equation}
\begin{gathered}
X_t=A(\theta)S_t+N_t,
\end{gathered}
\end{equation}
где $S_t \sim CN(\mathbf{O}_{M \times 1},\mathbf{P}),t=\overline{1,G}$, $N_t \sim CN(\mathbf{O}_{L \times 1}, \mathbf{\Lambda})$,  $\theta=[\theta_1,...,\theta_M]^T$ --- вектор направлений прибытия сигнала, $A(\theta)$ (далее -- $A$) представляет собой матрицу управляющих векторов размера $L \times M$, $\mathbf{P}$ и $\mathbf{\Lambda}$ предполагаются диагональными. Рассматривается случай, когда массив антенн является линейным и равномерным.
\begin{gather}
A(\theta) = \begin{bmatrix}
1&1&\dots&1\\
e^{-2j\pi \frac{d}{\lambda}\sin(\theta_1)}& e^{-2j\pi \frac{d}{\lambda}\sin(\theta_2)}&\dots&e^{-2j\pi \frac{d}{\lambda}\sin(\theta_M)}\\
\dots&\dots&\ddots&\vdots\\
e^{-2j\pi (L-1) \frac{d}{\lambda}\sin(\theta_1)}& e^{-2j\pi (L-1) \frac{d}{\lambda}\sin(\theta_2)}&\dots&e^{-2j\pi (L-1) \frac{d}{\lambda}\sin(\theta_M)}\\
\end{bmatrix}.
\nonumber
\end{gather}
\end{itemize}
\begin{itemize}
\item
$L_{o_t}$ --- число исправных сенсоров в момент времени $t$;
\item
 $L_{m_t}$ --- число неисправных сенсоров в момент времени $t$;
\item 
$A_{o_t}$ --- матрица, образованная теми строками матрицы $A$, которые соответствуют работающим сенсорам в момент времени $t$; 
\item
$A_{m_t}$ --- матрица, образованная теми строками матрицы $A$, которые соответствуют неисправным сенсорам в момент времени $t$;
\item
$\mathbf{\Lambda}_{m_t}$ --- ковариационная матрица шума на неисправных сенсорах в момент времени $t$;
\item 
 $\mathbf{\Lambda}_{o_t}$ --- ковариационная матрица шума на исправных сенсорах в момент времени $t$.
\end{itemize}
Рассмотрим 2 случая:
\begin{itemize}
\item
Известный шум
\item
Неизвестный шум
\end{itemize}
\begin{center}
\fontsize{16}{20}\selectfont \color{teal}{\textbf{\S1 Известный шум}}
\end{center}
Воспользуемся ECM-алгоритмом для того, чтобы определить значения параметров $\Psi = (\theta, \mathbf{P})$, пропущенные значения $X_m=\{X_{m_t}\}_{t=1}^G$ рассматриваются как латентные переменные.
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Е-шаг}}
\end{center}
Требуется найти условное математическое ожидание с учетом апостериорного распределения ненаблюдаемых/пропущенных принятых сигналов и текущей оценки параметров
\begin{equation}
 \Expect_{X_m|X_o=x_o, \Psi^{(\tau)}}[\log P(X_o, X_m)]
\end{equation}
Сначала найдем апостериорное распределение $P(X_m|X_o=x_o,\Psi)$, воспользуемся формулой Байеса:
\begin{gather}
P(X_m|X_o=x_o,\Psi) = \frac{P(X_o, X_m|\Psi)}{P(X_o|\Psi)} = \frac{P(X|\Psi)}{P(X_o|\Psi)}
\end{gather}
\begin{gather*}
X_t = AS_t + N_t \\
X_t \sim CN(\mathbf{O}_{L \times 1}, A\mathbf{P}A^H + \mathbf{\Lambda})\\
X_{o_t} \sim CN(\mathbf{O}_{L \times 1}, A_{o_t}\mathbf{P}A_{o_t}^H + \mathbf{\Lambda_{o_t}})\\
\end{gather*}
\begin{gather}
P(X|\Psi) = \prod_{t=1}^G \frac{1}{\pi^L \Det(\mathbf{\Lambda})}e^{-X_t^H (\mathbf{\Lambda})^{-1}X_t},
\end{gather}
\begin{gather}
P(X_o|\Psi) = \prod_{t=1}^G \frac{1}{\pi^{L_{o_t}} \Det(\mathbf{\Lambda}_{o_t})}e^{-(X_{o_t})^H (\mathbf{\Lambda}_{o_t})^{-1}(X_{o_t})},
\end{gather}
Параметры апостериорного распределения $P(X_{m_t}|X_{o_t}=x_{o_t},\Psi)$ можно найти исходя из следующих формул:
\begin{equation}
\left\{ \begin{aligned} 
m_{x_{m_t}|x_{o_t}} &= m_{x_{m_t}} + K_{x_{m_t},x_{o_t}}K_{x_{o_t},x_{o_t}}^{-1}\cdot(x_{o_t}-m_{x_{o_t}}) \\
K_{x_{m_t}|x_{o_t}} &= K_{x_{m_t},x_{m_t}}-K_{x_{m_t},x_{o_t}}K_{x_{o_t},x_{o_t}}^{-1}K_{x_{o_t},x_{m_t}}.
\end{aligned} \right.
\end{equation}
В рамках данной задачи:
\begin{equation}
\left\{ \begin{aligned} 
K_{x_{o_t},x_{o_t}} &= A_{o_t}\mathbf{P} A_{o_t}^H +\mathbf{\Lambda}_{o_t} \\
K_{x_{o_t},x_{m_t}} &= A_{o_t}\mathbf{P} A_{m_t}^H \\
K_{x_{m_t},x_{o_t}} &= A_{m_t}\mathbf{P} A_{o_t}^H \\
K_{x_{m_t},x_{m_t}} &= A_{m_t}\mathbf{P} A_{m_t}^H + \mathbf{\Lambda}_{m_t} \\
m_{x_{o_t}}&=\mathbf{O}_{L_{o_t} \times 1} \\
m_{x_{m_t}}&=\mathbf{O}_{L_{m_t} \times 1}
\end{aligned} \right.
\end{equation}
\begin{equation}
\left\{ 
\begin{aligned}
 m_{x_{m_t}|x_{o_t}} &= A_{m_t}\mathbf{P} A_{o_t}^H(A_{o_t}\mathbf{P} A_{o_t}^H + \mathbf{\Lambda}_{o_t})^{-1}\cdot x_{o_t} \\
K_{x_{m_t}|x_{o_t}} &= A_{m_t}\mathbf{P} A_{m_t}^H + \mathbf{\Lambda}_{m_t}-A_{m_t}\mathbf{P} A_{o_t}^H(A_{o_t}\mathbf{P} A_{o_t}^H + \mathbf{\Lambda}_{o_t})^{-1}A_{o_t}\mathbf{P} A_{m_t}^H,
\end{aligned}
\right.
\end{equation}
Оцениваем пропущенные значения для каждого наблюдения через условное математическое ожидание:
$\hat{x}_{m_t} = m_{x_{m_t}|x_{o_t}}$.
Вернемся к ранее рассмотренному условному математическому ожиданию:
\begin{equation*}
 \Expect_{X_m|X_o=x_o, \Psi^{(\tau)}}[\log P(X_o, X_m)].
\end{equation*}
Его следует максимизировать, мы можем перейти от логарифма произведения к сумме логарифмов. Определим, как будет выглядеть это УМО для произвольно выбранного элемента выборки $X_t$:
\begin{equation*}
\begin{gathered}
 \Expect_{X_m|X_o=x_o, \Psi^{(\tau)}}[\log P(X_o, X_m)] = \\
 \sum_{t=1}^G\Expect_{X_{m_t}|X_{o_t}=x_{o_t}, \Psi^{(\tau)}}[\log P(X_{o_t}, X_{m_t})]
\end{gathered}
\end{equation*}
\\
\\
\begin{equation*}
\begin{gathered}
\Expect_{X_{m_t}|X_{o_t}=x_{o_t}, \Psi^{(\tau-1)}}[\log P(X_{o_t}, X_{m_t})]=\\
\Expect_{\Psi^{(\tau-1)}}\Big[\log P\Big(X_{o_t}, X_{m_t}\Big|X_{m_t}|X_{o_t}=x_{o_t}\Big)\Big]=\\
\Expect_{\Psi^{(\tau-1)}}\bigg[\log \left(\frac{1}{\pi^{L}\Det(\Sigma)}e^{-(X_t-\mu)^H\Sigma^{-1}(X_t-\mu)}\right)\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg]=\\
\Expect_{\Psi^{(\tau-1)}}\bigg[-L \log(\pi) - \log (\Det(\Sigma)) - (X_t - \mu)^H\Sigma^{-1}(X_t - \mu)\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg]=\\
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})})) + \\ + \Expect_{\Psi^{(\tau-1)}}\bigg[- (X_t - \mu)^H\Sigma^{-1}(X_t - \mu)\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg]=\\
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})}))  + \\ + \Expect_{\Psi^{(\tau-1)}}\bigg[- 
\begin{bmatrix} X_{m_t} - \mu_{X_{m_t}} \\  X_{o_t} - \mu_{X_{o_t}} \end{bmatrix}^H \Sigma^{-1}
\begin{bmatrix} X_{m_t} - \mu_{X_{m_t}} \\  X_{o_t} - \mu_{X_{o_t}} \end{bmatrix}\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg] = \\
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})}))  + \\ + \Expect_{\Psi^{(\tau-1)}}\bigg[- 
\begin{bmatrix} X_{m_t} \\  X_{o_t} \end{bmatrix}^H
\begin{bmatrix} \Sigma_{(m_t, m_t)} & \Sigma_{(m_t, o_t)} \\  \Sigma_{(o_t, m_t)} & \Sigma_{(o_t, o_t)} \end{bmatrix}^{-1}
\begin{bmatrix} X_{m_t} \\  X_{o_t} \end{bmatrix}\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg] = \\
\end{gathered}
\end{equation*}

\begin{equation*}
\begin{gathered}
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})}))  - \\ 
- \Expect_{\Psi^{(\tau-1)}}\bigg[X_{m_t}^H (\Sigma^{-1})_{(m_t, m_t)}X_{m_t} + 2 X_{o_t}^H (\Sigma^{-1})_{(m_t, o_t)}X_{m_t}  + X_{o_t}^H (\Sigma^{-1})_{(m_t, m_t)}X_{o_t}\Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg] = \\
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})}))  - \\ 
- x_{o_t}^H (\Sigma^{-1})_{(o_t, o_t)}x_{o_t} - 2 x_{o_t}^H (\Sigma^{-1})_{(m_t, o_t)}\hat{x}_{m_t}^{(\tau)} - \Expect_{\Psi^{(\tau-1)}}\bigg[X_{m_t}^H (\Sigma^{-1})_{(m_t, m_t)}X_{m_t}   \Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg] \\
\end{gathered}
\end{equation*}
Заметим, что: 
\begin{equation*}
[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}X_{m_t} \sim N\Big([(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\hat{x}_{m_t}^{(\tau)},[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}}[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\Big)
\end{equation*}
Выполняем последующие преобразования, используя тот факт, что: $\Expect(WW^H)=\Cov(W,W)+\Expect(W)\Expect(W)^H$.
\begin{equation*}
\begin{gathered}
\Expect_{\Psi^{(\tau-1)}}\bigg[X_{m_t}^H (\Sigma^{-1})_{(m_t, m_t)}X_{m_t}   \Big|X_{m_t}|X_{o_t}=x_{o_t}\bigg] = \\
\Expect_{\Psi^{(\tau-1)},X_{m_t}|X_{o_t}=x_{o_t}}\bigg[\Big[[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}}\Big]^H\Big[[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}}\Big]\bigg] = \\
\Expect_{\Psi^{(\tau-1)},X_{m_t}|X_{o_t}=x_{o_t}}[W_t^HW_t] = \\
\Tr \Big( \Expect_{\Psi^{(\tau-1)},X_{m_t}|X_{o_t}=x_{o_t}}[W_tW_t^H] \Big) = \\
\Tr \Big( \big[(\Sigma^{-1})_{(m_t, m_t)}\big]^{\frac{1}{2}}\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}}\big[(\Sigma^{-1})_{(m_t, m_t)}\big]^{\frac{1}{2}} \Big) +  \Tr \Big( \big[[(\Sigma^{-1})_{(m_t, m_t)}]^{\frac{1}{2}}\hat{x}_{m_t}^{(\tau)}\big]\big[[(\Sigma^{-1})_{(m_t, m_t)}\big]^{\frac{1}{2}}\hat{x}_{m_t}^{(\tau)}]^H \Big)= \\
\Tr \Big( \big[(\Sigma^{-1})_{(m_t, m_t)}\big]\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \Big) + \Tr \Big((\hat{x}_{m_t}^{(\tau)})^H\big[(\Sigma^{-1})_{(m_t, m_t)}\big]\hat{x}_{m_t}^{(\tau)} \Big) \\
\end{gathered}
\end{equation*}
\begin{equation*}
\begin{gathered}
\Expect_{X_{m_t}|X_{o_t}=x_{o_t}, \Psi^{(\tau-1)}}[\log P(X_{o_t}, X_{m_t})]=\\
-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})})) - x_{o_t}^H (\Sigma^{-1})_{(o_t, o_t)}x_{o_t} - 2 x_{o_t}^H (\Sigma^{-1})_{(m_t, o_t)}\hat{x}_{m_t}^{(\tau)} - \\ \Tr \Big( [(\Sigma^{-1})_{(m_t, m_t)}]\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \Big) - \Tr \Big((\hat{x}_{m_t}^{(\tau)})^H[(\Sigma^{-1})_{(m_t, m_t)}]\hat{x}_{m_t}^{(\tau)} \Big) 
\end{gathered}
\end{equation*}
Таким образом, оптимизируемая функция примет следующий вид:
\begin{equation*}
\begin{gathered}
 \Expect_{X_m|X_o=x_o, \Psi^{(\tau)}}[\log P(X_o, X_m)] = \\
 \sum_{t=1}^G\Expect_{X_{m_t}|X_{o_t}=x_{o_t}, \Psi^{(\tau)}}[\log P(X_{o_t}, X_{m_t})] = \\
\sum_{t=1}^G \bigg[-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})})) - x_{o_t}^H (\Sigma^{-1})_{(m_t, m_t)}x_{o_t} - 2 x_{o_t}^H (\Sigma^{-1})_{(m_t, o_t)}\hat{x}_{m_t}^{(\tau)} - \\ \Tr \Big( [(\Sigma^{-1})_{(m_t, m_t)}]\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \Big) - \Tr \Big((\hat{x}_{m_t}^{(\tau)})^H[(\Sigma^{-1})_{(m_t, m_t)}]\hat{x}_{m_t}^{(\tau)} \Big) \bigg]
\end{gathered}
\end{equation*}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{M-шаг}}
\end{center}
Требуется найти наилучшую оценку параметров, решив следующую задачу оптимизации:
\begin{equation*}
\begin{gathered}
\Psi^{(\tau)}=\argmax_{\Psi} \Expect_{X_m|X_o=x_o, \Psi^{(\tau-1)}}[\log P(X_o, X_m)] =\\
\argmax_{\Psi} \sum_{t=1}^G \bigg[-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})})) - x_{o_t}^H (\Sigma^{-1})_{(m_t, m_t)}x_{o_t} - 2 x_{o_t}^H (\Sigma^{-1})_{(m_t, o_t)}\hat{x}_{m_t}^{(\tau)} - \\ \Tr \Big( [(\Sigma^{-1})_{(m_t, m_t)}]\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \Big) - \Tr \Big((\hat{x}_{m_t}^{(\tau)})^H[(\Sigma^{-1})_{(m_t, m_t)}]\hat{x}_{m_t}^{(\tau)} \Big) \bigg]
\end{gathered}
\end{equation*}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Первый СM-шаг}}
\end{center}
Оценим углы прибытия сигналов $\theta$, но оставляем оценку ковариации сигналов $\mathbf{P}$ фиксированной: $\mathbf{P} = \mathbf{P}^{(\tau-1)}$.
\begin{equation*}
\begin{gathered}
\theta^{(\tau)}= \argmax_{\theta} Q(\theta | \theta^{(\tau-1)}) = \\
\argmax_{\theta} \sum_{t=1}^G \bigg[-L \log(\pi) - \log (\Det(\Sigma_{X_t|(X_{m_t}|X_{o_t}=x_{o_t})})) - x_{o_t}^H (\Sigma^{-1})_{(m_t, m_t)}x_{o_t} - 2 x_{o_t}^H (\Sigma^{-1})_{(m_t)(o_t)}\hat{x}_{m_t}^{(\tau)} - \\ \Tr \Big( [(\Sigma^{-1})_{(m_t, m_t)}]\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \Big) - \Tr \Big((\hat{x}_{m_t}^{(\tau)})^H[(\Sigma^{-1})_{(m_t, m_t)}]\hat{x}_{m_t}^{(\tau)} \Big) \bigg]
\end{gathered}
\end{equation*}
Внутри данной функции, вектор $\theta$ возникает только как переменная, влияющая на $\Sigma$. Если будет найдено оптимальное значение $\Sigma^{(\tau)}$ матрицы $\Sigma$, можно будет найти $\theta$, 
численно решив $A(\theta^{(\tau)}) \mathbf{P}A(\theta^{(\tau)})^H + \mathbf{\Lambda} = \Sigma^{(\tau)}$ относительно $\theta$. \\
Пусть $\widetilde{x}_t^{(\tau)}$ --- вектор $x_t$, в котором пропущенные значения $x_{m_t}$ оценены с помощью $\hat{x}_{m_t}^{(\tau)}$.
\begin{align*}
\nabla_{\Sigma^{-1}} Q(\theta \text{ | } \theta^{(\tau-1)}) &= \sum_{t = 1}^{G} \nabla_{\Sigma^{-1}} Q_t (\theta \text{ | } \theta^{(\tau-1)}) \\
&= \sum_{t = 1}^{G} \frac{1}{2} \nabla_{\Sigma^{-1}} \log |\Sigma^{-1}| - \frac{1}{2} \nabla_{\Sigma^{-1}} \Tr \big( (\Sigma^{-1})_{(m_t, m_t)} \Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \big) \\
&\hspace{10pt} - \sum_{t = 1}^{G} \frac{1}{2} \nabla_{\Sigma^{-1}} (\widetilde{x}_t^{(\tau)})^H \Sigma^{-1} \widetilde{x}_t^{(t)} \\
&= \frac{1}{2} \sum_{t = 1}^{G} \nabla_{\Sigma^{-1}} \log |\Sigma^{-1}| - \nabla_{\Sigma^{-1}} \Tr \big( (\Sigma^{-1})_{(m_t, m_t)} \Sigma^{(\tau)}_{x_{m_t}|x_{o_t}} \big) \\
&\hspace{10pt} - \frac{1}{2} \sum_{t = 1}^{G} \nabla_{\Sigma^{-1}} \Tr \big( (\widetilde{x}_t^{(\tau)})^H \Sigma^{-1} \widetilde{x}_t^{(\tau)} \big)
\end{align*}
\begin{align*}
\nabla_{\Sigma^{-1}} Q(\theta \text{ | } \theta^{(\tau-1)}) &= \frac{1}{2} \big[ \sum_{t = 1}^{G} \Sigma -  \widetilde{\Sigma}_{t}^{(\tau)} \big] - \frac{1}{2} \sum_{t = 1}^{G} \widetilde{x}_t^{(\tau)}(\widetilde{x}_t^{(\tau)})^H \\
&= \frac{1}{2} \big[ G \Sigma - \sum_{t = 1}^{G} \widetilde{\Sigma}_{t}^{(\tau)} \big] - \frac{1}{2} \sum_{t = 1}^{G} \widetilde{x}_t^{(\tau)}(\widetilde{x}_t^{(\tau)})^H
\end{align*}
где $\Sigma_{t}^{(\tau)}$ --- матрица размера $L \times L$, в которой все элементы являются нулями, за исключением тех, что стоят на пересечении строк с номерами $(m_t)$ и столбцов с номерами $(m_t)$: они заменены величиной $\Sigma^{(\tau)}_{x_{m_t}|x_{o_t}}$.
Приравняем производную к нулю, чтобы получить значение $\Sigma$, соответствующее максимуму.
\begin{align*}
O &= \frac{1}{2} \big[ G \Sigma^{(\tau)} - \sum_{t = 1}^{G} \widetilde{\Sigma}_{t}^{(\tau)} \big] - \frac{1}{2} \sum_{t = 1}^{G} \widetilde{x}_t^{(\tau)}(\widetilde{x}_t^{(\tau)})^H \\
&= \big[ G \Sigma^{(\tau)} - \sum_{t = 1}^{G} \widetilde{\Sigma}_{t}^{(\tau)} \big] - \sum_{t = 1}^{G} \widetilde{x}_t^{(\tau)}(\widetilde{x}_i^{(\tau)})^H \\
\iff G \Sigma^{(\tau)} &= \sum_{t = 1}^{G} \widetilde{\Sigma}_{t}^{(\tau)} + \sum_{t = 1}^{G} \widetilde{x}_t^{(\tau)}(\widetilde{x}_t^{(\tau)})^H \\
\iff \Sigma^{(\tau)} &= \frac{1}{G} \sum_{t = 1}^{G} \Big[ \widetilde{\Sigma}_{t}^{(\tau)} + \widetilde{x}_t^{(\tau)}(\widetilde{x}_t^{(\tau)})^H \Big]
\end{align*}
Можем теперь численно решить следующее уравнение относительно $\theta^{(\tau)}$:
\begin{equation}
A(\theta^{(\tau)})\mathbf{P}^{(\tau-1)}A(\theta^{(\tau)})^H + \mathbf{\Lambda} = \Sigma^{(\tau)}.
\end{equation}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Второй СM-шаг}}
\end{center}
Оценим ковариацию сигналов $\mathbf{P}$, но оставляем оценку углов прибытия сигналов $\theta$ фиксированной: $\theta = \theta^{(\tau)}$
Можем теперь численно решить следующее уравнение относительно $\mathbf{P}^{(\tau)}$:
\begin{equation}
A(\theta^{(\tau)})\mathbf{P}^{(\tau)}A(\theta^{(\tau)})^H + \mathbf{\Lambda} = \Sigma^{(\tau)}.
\end{equation}
\begin{center}
\fontsize{16}{20}\selectfont \color{teal}{\textbf{\S2 Неизвестный шум}}
\end{center}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Е-шаг}}
\end{center}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{M-шаг}}
\end{center}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Первый СM-шаг}}
\end{center}
\begin{center}
\fontsize{14}{18}\selectfont \color{red}{\textbf{Второй СM-шаг}}
\end{center}
\begin{center}
\fontsize{16}{20}\selectfont \color{teal}{\textbf{Список источников}}
\end{center}
\end{document}
