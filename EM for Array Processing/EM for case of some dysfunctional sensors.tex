\documentclass[11pt]{article}
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, left=2.5cm, right=1.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{animate} 
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{tikz}
\usepackage{comment}
\usepackage{animate} 
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{tikz}
\usepackage{comment}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{cancel}
\usepackage{mathtools}
\usepackage[most]{tcolorbox}
\usepackage[mathscr]{euscript}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
 
\newcommand{\Expect}{\mathsf{M}}
\newcommand{\Var}{\mathsf{D}}
\newcommand{\Cov}{\mathsf{cov}}
\newcommand{\Norm}{\mathcal{N}}
\newcommand{\NormComplex}{\mathcal{CN}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Int}{\mathbb{Z}}
\newcommand{\XSig}{\mathbf{x}}
\newcommand{\Ssig}{\mathbf{s}}
\newcommand{\Nsig}{\mathbf{n}}
\newcommand{\Rs}{\mathbf{R}_s}
\newcommand{\Rn}{\mathbf{R}_n}
\newcommand{\DK}{\mathbf{D}_{KL}}
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\infdiv}{D_{KL}\infdivx}
\newcommand\Fontvi{\fontsize{8.2}{7.2}\selectfont}
\newcommand\Fontvia{\fontsize{9}{8}\selectfont}
\newcommand\Fontvib{\fontsize{10.8}{9.6}\selectfont}
\newcommand\Fontvic{\fontsize{8.0}{7.0}\selectfont}
\newcommand{\myitem}{\item[\checkmark]}
%\newcommand{\myitem}{\item[\squares]}

\begin{document}
\begin{center}
\fontsize{20}{23}\selectfont \color{red}{\textbf{ЕМ-алгоритм для оценки направления прибытия сигнала}}
\end{center}
Введем некоторые условные обозначения:
\begin{itemize}
\item
$\theta$ -- вектор направлений прибытия сигнала (DOA);
\item
$\tau$ -- итерация ЕМ-алгоритма, начальная оценка параметров $\theta$;
\item
$t$ -- момент времени (а заодно и номер кадра (snapshot));
\item
$L$ -- число датчиков;
\item
$M$ -- число источников (источники разделяют общую длину центральной волны $\chi$);
\item
$G$ -- число независимых кадров/снимков (snapshot), сделанных в разные моменты времени;
\item
$S$ -- набор сигналов (случайная величина), испускаемых источниками в моменты времени $t=\overline{1,G}$, $S_t$ соответствует сигналу в момент времени $t$;
\item
$s$ -- набор сигналов (реализация), испускаемых источниками в моменты времени $t=\overline{1,G}$, $s_t$ соответствует сигналу в момент времени $t$;
\item
$N$ -- набор шумов (случайная величина), связанных с датчиками в моменты времени $t=\overline{1,G}$, $N_t$ соответствует шуму в момент времени $t$;
\item
$n$ -- набор шумов (реализация), связанных с датчиками в моменты времени $t=\overline{1,G}$, $n_t$ соответствует шуму в момент времени $t$;
\item
$X$ -- набор сигналов (случайная величина), полученных датчиками в моменты времени $t=\overline{1,G}$, $X_t$ соответствует сигналу в момент времени $t$;
\item
$x$ -- набор сигналов (реализация), полученных датчиками в моменты времени $t=\overline{1,G}$, $x_t$ соответствует сигналу в момент времени $t$;
\item
$X_o$ -- наблюдаемая часть (случайная величина) $X$, $X_{o,t}$ соответствует сигналу в момент времени $t$; 
\item
$x_o$ -- наблюдаемая часть (реализация) $X$, $x_{o,t}$ соответствует сигналу в момент времени $t$;
\item
$X_m$ -- ненаблюдаемая часть (случайная величина) $X$, $X_{m,t}$ соответствует сигналу в момент времени $t$;
\item
$x_m$ -- ненаблюдаемая часть (реализация) $X$, $x_{m,t}$ соответствует сигналу в момент времени $t$;
\item
$Y$ -- латентные переменные (случайная величина) ($X_m, S$);
\item
$y$ -- латентные переменные (реализация) ($x_m, s$);
\item
$\psi$ -- параметры комплексного нормального распределения $X_m$;
\item
$\Omega$ -- $(\psi, \theta)$;
\item
$O_{D_1 \times D_2}$ -- нулевая матрица размера $D_1 \times D_2$;
\item
Полученный сигнал (итоговый сигнал, получаемый массивом датчиков):
\begin{equation}
\begin{gathered}
X_t=A(\theta)S_t+N_t,
\end{gathered}
\end{equation}
где $S_t \sim CN(0,\Gamma_s),t=\overline{1,G}$, $N_t \sim CN(0,\Gamma_n), t=\overline{1,G}$, $S_t$ имеет размер $M \times 1$,  $N_t$ имеет размер $L \times 1$, $\theta=[\theta_1,...,\theta_M]$ -- вектор направлений прибытия сигнала, $A(\theta)$ (далее - $A$) представляет собой матрицу управляющих векторов размера $L \times M$, $\Gamma_s$ и $\Gamma_n$ предполагаются диагольными.
\begin{gather}
A(\theta) = \begin{bmatrix}
1&1&\dots&1\\
e^{-2j\pi \frac{d}{\lambda}sin(\theta_1)}& e^{-2j\pi \frac{d}{\lambda}sin(\theta_2)}&\dots&e^{-2j\pi \frac{d}{\lambda}sin(\theta_M)}\\
\dots&\dots&\ddots&\vdots\\
e^{-2j\pi (L-1) \frac{d}{\lambda}sin(\theta_1)}& e^{-2j\pi (L-1) \frac{d}{\lambda}sin(\theta_2)}&\dots&e^{-2j\pi (L-1) \frac{d}{\lambda}sin(\theta_M)}\\
\end{bmatrix}.
\nonumber
\end{gather}
\end{itemize}
Воспользуемся ЕМ-алгоритмом для того, чтобы определить значения параметров $\theta$, значения сигналов $S_t, t=\overline{1,G}$ рассматриваются как латентные переменные. 
Пусть $X$, $S$ и $N$ набор итоговых сигналов полученных $L$ датчиками за моменты времени $t=\overline{1,G}$ и набор выпущенных $M$ источниками сигналов и набор шумов за моменты времени $t=\overline{1,G}$, соответственно. $X$, $S$ и $N$ представляют из себя матрицы размеров $G \times L$, $G \times M$ и $G \times L$ соответственно.
\begin{center}
\fontsize{16}{20}\selectfont \color{red}{\textbf{Е-шаг}}
\end{center}
Требуется найти апостериорное распределение $P(Y|X_o=x_o,\theta)$, воспользуемся формулой Байеса:
\begin{gather}
P(Y|X_o=x_o,\theta) = P(X_m, S|X_o=x_o,\theta) = \frac{P(X, S|\theta)}{P(X_m, S|\theta)} = \frac{P(X_o, X_m, S|\theta)}{P(X_m, S|\theta)} = \frac{P(X_o, X_m, S|\theta)}{P(X_m|S=s, \theta)P(S|\theta)} 
\end{gather}
\begin{gather}
P(S|\theta) = \prod_{t=1}^G \frac{1}{\pi^M |\Gamma_s|}e^{-S_t^H\Gamma_s^{-1}S_t},
\end{gather}
\begin{gather*}
X_t = AS_t + N_t \\
X_t \sim CN(0, A\Gamma_s A^H + \Gamma_n)
\end{gather*}
\begin{gather}
P(X|\theta) = \prod_{t=1}^G \frac{1}{\pi^L |A\Gamma_s  A^H + \Gamma_n|}e^{-X_t^H (A\Gamma_s A^H + \Gamma_n)^{-1}X_t},
\end{gather}
Теперь следует определиться с тем, каким будет условное распределение $P(X|S=s, \theta)$
\begin{gather*}
X_t|S_t=s_t, \theta \, \sim CN(A s_t, \Gamma_n)
\end{gather*}
\begin{gather}
P(X|S=s,\theta) = \prod_{t=1}^G \frac{1}{\pi^L |\Gamma_n|}e^{-(X_t-A s_t)^H \Gamma_n^{-1}(X_t-A s_t)},
\end{gather}
Теперь следует найти $P(X_m|S=s, \theta)$. Введем новые обозначения: пусть
\begin{itemize}
\item 
$A_{o,t}$ -- матрица, образованная теми строками матрицы $A$, которые соответствуют работающим сенсорам в момент времени $t$; 
\item
$A_{m,t}$ -- матрица, образованная теми строками матрицы $A$, которые соответствуют неисправным сенсорам в момент времени $t$;
\item
$\Gamma_{m,t}$ -- ковариационная матрица шума на неисправных сенсорах в момент времени $t$;
\item 
 $\Gamma_{o,t}$ -- ковариационная матрица шума на исправных сенсорах в момент времени $t$;
\item
$L_{1,t}$ -- число исправных сенсоров в момент времени $t$;
\item
 $L_{2,t}$ -- число неисправных сенсоров в момент времени $t$.
\end{itemize}
\begin{gather}
P(X_{m,t}|S_t=s_t,\theta) = \prod_{t=1}^G \frac{1}{\pi^{L_2} |\Gamma_{m,t}|}e^{-(X_{m,t}-A_{m,t} s_t)^H \Gamma_{m,t}^{-1}(X_{m,t}-A_{m,t} s_t)},
\end{gather}
\begin{equation}
\left\{ \begin{gathered} 
\Sigma_{Y_t|X_{o,t}} = \Sigma_{Y_t}-\Sigma_{Y_t,X_{o,t}}\Sigma_{X_{o,t}}^{-1}\Sigma_{X_{o,t},Y_t} \\
\mu_{Y_t|X_{o,t}} = \mu_{Y_t} + \Sigma_{Y_t,X_{o,t}}\Sigma_{X_{o,t}}^{-1}\cdot(x_{o,t}-\mu_{X_{o,t}}),
\end{gathered} \right.
\end{equation}
\begin{gather}
\Sigma_{X_{o,t}}=A_{o,t}\Gamma_sA_{o,t}^H+\Gamma_{o,t}
\end{gather}
\begin{gather}
\Sigma_{Y_t} = \begin{pmatrix}
\Sigma_{X_{m,t}}&\Sigma_{X_{m,t}, S_t}\\
\Sigma_{S_t, X_{m,t}}&\Sigma_{S_t}
\end{pmatrix}
\end{gather}
\begin{gather}
\Sigma_{S_t} = \Gamma_s
\end{gather}
\begin{gather}
\Sigma_{X_{m,t}} = A_{m,t} \Gamma_s A_{m,t}^H + \Gamma_{m,t}
\end{gather}
\begin{gather}
\Sigma_{X_{m,t},S_t} = A_{m,t} \Gamma_s, \Sigma_{S_t, X_{m,t}} = \Gamma_s A_{m,t}^H 
\end{gather}
\begin{gather}
\Sigma_{Y_t} = \begin{pmatrix}
A_{m,t} \Gamma_s A_{m,t}^H + \Gamma_{m,t}&A_{m,t} \Gamma_s\\
\Gamma_s A_{m,t}^H&\Gamma_s
\end{pmatrix}
\end{gather}
\begin{gather}
\Sigma_{X_{o,t},Y_t}
= \begin{pmatrix}
\Sigma_{X_{o,t},X_{m,t}}\\
\Sigma_{X_{o,t},S_t}
\end{pmatrix}= 
\begin{pmatrix}
A_{o,t}\Gamma_s A_{m,t}^H\\
A_{o,t}\Gamma_s
\end{pmatrix}
\end{gather}
\begin{gather}
\Sigma_{Y_t,X_{o,t}}
= \Sigma_{X_{o,t},Y_t}^H
\end{gather}
\begin{equation}
\left\{ \begin{gathered} 
\Sigma_{Y_t|X_{o,t}} = \begin{pmatrix}
\Sigma_{X_{m,t}}&\Sigma_{X_{m,t}, S_t}\\
\Sigma_{S_t, X_{m,t}}&\Sigma_{S_t}
\end{pmatrix}-\begin{pmatrix}
\Sigma_{X_{o,t},X_{m,t}}\\
\Sigma_{X_{o,t},S_t}
\end{pmatrix}^H(\Sigma_{X_{o,t}})^{-1}\begin{pmatrix}
\Sigma_{X_{o,t},X_{m,t}}\\
\Sigma_{X_{o,t},S_t}
\end{pmatrix} \\
\mu_{Y_t|X_{o,t}} =   \begin{pmatrix}
\Sigma_{X_{o,t},X_{m,t}}\\
\Sigma_{X_{o,t},S}
\end{pmatrix}^H(\Sigma_{X_{o,t}})^{-1}\cdot x_o,
\end{gathered} \right.
\end{equation}
\begin{equation}
\left\{ \begin{gathered} 
\Sigma_{Y_t|X_{o,t}} = \begin{pmatrix}
A_{m,t} \Gamma_s A_{m,t}^H + \Gamma_m&A_{m,t} \Gamma_s\\
\Gamma_s A_{m,t}^H&\Gamma_s
\end{pmatrix}- \begin{pmatrix}
A_{o,t}\Gamma_s A_{m,t}^H\\
A_{o,t}\Gamma_s
\end{pmatrix}^H(A_{o,t}\Gamma_sA_{o,t}^H+\Gamma_{o,t})^{-1} \begin{pmatrix}
A_{o,t}\Gamma_s A_{m,t}^H\\
A_{o,t}\Gamma_s
\end{pmatrix} \\
\mu_{Y|X_o} =   \begin{pmatrix}
A_{o,t}\Gamma_s A_{m,t}^H\\
A_{o,t}\Gamma_s
\end{pmatrix}^H(A_{o,t}\Gamma_sA_{o,t}^H+\Gamma_{o,t})^{-1}\cdot x_{o,t},
\end{gathered} \right.
\end{equation}
\begin{center}
\fontsize{16}{20}\selectfont \color{red}{\textbf{M-шаг}}
\end{center}
Требуется найти наилучшую оценку параметров, решив следующую задачу оптимизации:
\begin{gather}
\theta^{(\tau+1)}=\argmax_{\theta} E[\log P(X_o, X_m, \, S|\theta^{(\tau)})|X_o=x_o, \theta^{(\tau)}] = E\left[\sum_{t=1}^G\log P(X_{o,t}, X_{m,t}, \, S_t|\theta^{(\tau)})|X_{o,t}=x_{o,t}, \theta^{(\tau)}\right]
\end{gather}
Обозначим приведенное выше условное математическое ожидание через $Q$. 
Заметим, что \\ $\log P(X_{o,t}, \, X_{m,t}, \, S_t|\theta^{(\tau)}) = \log P(X_{o,t}|X_{m,t}, \, S_t,\theta^{(\tau)})P(X_{m,t}, S_t|\theta^{(\tau)}) = \log P(X_{o,t}|Y_t,\theta^{(\tau)})P(Y_t|\theta^{(\tau)})$.\\
Можно заметить, что $P(X_{o,t}|Y_t, Y_t) = P(X_{o,t}, Y_t)$. Работать с плотостью $P(X_{o,t}|Y_t, Y_t)$ удобнее: кросс-ковариция между $Y$ и $X_o|Y$ будет представлять из себя нулевую матрицу.
Найдем совместную плотность $P(X_o|Y, \, Y|\theta^{(\tau)})$:
\begin{gather}
P(X_o|Y, \, Y|\theta^{(\tau)}) = \prod_{t=1}^G \frac{1}{\pi^{M+L}|\Sigma|}e^{-(Z_t-\mu_{Z_t})^H\Sigma^{-1}(Z_t-\mu_{Z_t})},
\end{gather}
где:
\begin{equation*}
Z_t = \begin{pmatrix}
Y_t\\
X_{o,t}|Y_t
\end{pmatrix},
\mu_{Y_t} = \begin{pmatrix}
\mu_{Y_t}\\
\mu_{X_{o,t}|Y_t}
\end{pmatrix}\\,
\Sigma = 
\begin{pmatrix}
\Sigma_{Y_t}&O_{(M+L_2)\times (L-L_2)}\\
O_{(L-L_2)\times (M+L_2)}&\Sigma_{X_{o,t}|Y_t}
\end{pmatrix}
\end{equation*}
Найдем логарифм совместной плотности (т.е. полное правдоподобие) $\log P(X_o|Y, \, Y|\theta^{(\tau)})$:
\begin{equation*}
\log P(X_o|Y, \, Y|\theta^{(\tau)}) = \sum_{t=1}^G \left(-(M+L)\log(\pi)-\log|\Sigma|-(Z_t-\mu_{Z_t})^H\Sigma^{-1}(Z_t-\mu_{Z_t})\right)
\end{equation*}
Теперь попробуем раскрыть УМО полного правдоподобия для одного наблюдения, с учетом полученных сигналов и текущей оценки DOA:
\begin{gather}
P(X_{o,t}|Y_t, \, Y_t|\theta^{(\tau)}) = \frac{1}{\pi^{M+L}|\Sigma|}e^{-(Z_t-\mu_{Z_t})^H\Sigma^{-1}(Z_t-\mu_{Z_t})}
\end{gather}
\begin{gather*}
Q_t = E[\log P(X_{o,t}|Y_t, \, Y_t|\theta^{(\tau)})|X_{o,t}, \theta^{(\tau)}] \\ = E[-(M+L)\log(\pi)-\log|\Sigma|-(Z_t-\mu_{Z_t})^H\Sigma^{-1}(Z_t-\mu_{Z_t})|X_{o,t}=x_{o,t}, \theta^{(\tau)}] = \\
=-(M+L)\log(\pi)-\log|\Sigma| - E[(Z_t-\mu_{Z_t})^H\Sigma^{-1}(Z_t-\mu_{Z_t})|X_{o,t}=x_{o,t}, \theta^{(\tau)}] \\
=-(M+L)\log(\pi)-\log|\Sigma|  -   E[(X_{o,t}|Y_t-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(X_{o,t}|Y_t-\mu_{X_{o,t}|Y_t})|X_{o,t}=x_{o,t}, \theta^{(\tau)}] 
\\- E[(Y_t-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(Y_t-\mu_{Y_t})|X_{o,t}=x_{o,t}, \theta^{(\tau)}] \\
=-(M+L)\log(\pi)-\log|\Sigma| - (x_t-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(x_t-\mu_{X_{o,t}|Y_t})\\ - E[(Y_t-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(Y_t-\mu_{Y_t})|X_{o,t}=x_{o,t},\theta^{(\tau)}] 
\end{gather*}
\begin{equation}
\begin{gathered}
Q_t = -(M+L)\log(\pi)-\log|\Sigma| - (x_t-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(x_t-\mu_{X_{o,t}|Y_t}) \\ - E[(Y_t-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(Y_t-\mu_{Y_t})|X_{o,t}=x_{o,t},\theta^{(\tau)}] 
\end{gathered}
\end{equation}
Заметим, что первые два слагаемые, составляющие $Q_t$, не зависят от $\theta$, соответственно требуемый $argmax [\cdot]$ можно найти без их учета.
\begin{gather*}
Y_t|(X_{o,t}=x_{o,t}, \theta^{(\tau)}) \sim CN(\mu_{Y_t|X_{o,t}}, \Sigma_{Y_t|X_{o,t}}) \Rightarrow Y_t-\mu_{Y_t}|(X_{o,t}=x_{o,t}, \theta^{(\tau)}) \sim CN(\mu_{Y_t|X_{o,t}}-\mu_{Y_t}, \Sigma_{Y_t|X_{o,t}})
\end{gather*}
\begin{gather*}
\Rightarrow [\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}( Y_t-\mu_{Y_t})|(X_{o,t}=x_{o,t}, \theta^{(\tau)}) \sim CN([\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t}),[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}} \Sigma_{Y_t|X_{o,t}}([\Sigma_{Y_t}^{-1}]^{\frac{1}{2}})^H)
\end{gather*}
Учтем, что для комплексных векторов $V$ выполняется следующее соотношение: 
\begin{gather}
E[VV^H]=E[V]E[V^H]+\Sigma_{VV}.
\end{gather}
\begin{gather*}
 E[(Y_t-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(Y_t-\mu_{Y_t})|X_{o,t}=x_{o,t},\theta^{(\tau)}]  =  E[[[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(Y_t-\mu_{Y_t})]^H[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(Y_t-\mu_{Y_t})|X_{o,t}=x_{o,t},\theta^{(\tau)}] =\\
= tr(E[[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(Y_t-\mu_{Y_t})[[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(Y_t-\mu_{Y_t})]^H]|X_{o,t}=x_{o,t},\theta^{(\tau)})=\\
= tr([\Sigma_{Y_t}^{-1}]^{\frac{1}{2}} \Sigma_{Y_t|X_{o,t}}([\Sigma_{Y_t}^{-1}]^{\frac{1}{2}})^H) + 
 tr([[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t})][[\Sigma_{Y_t}^{-1}]^{\frac{1}{2}}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t}]^H) = \\
= tr([\Sigma_{Y_t}^{-1}]\Sigma_{Y_t|X_{o,t}}) + (\mu_{Y_t|X_{o,t}}-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t})
\end{gather*}
\begin{equation}
\begin{gathered}
Q_t = -(M+L)\log(\pi)-\log|\Sigma| - (x_{o,t}-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(x_{o,t}-\mu_{X_{o,t}|Y_t}) \\ -  tr([\Sigma_{Y_t}^{-1}]\Sigma_{Y_t|X_{o,t}}) - (\mu_{Y_t|X_{o,t}}-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t}) 
\end{gathered}
\end{equation}
\begin{equation}
\begin{gathered}
 E[\log P(X_o, \, Y|\theta^{(\tau)})|X_o, \theta^{(\tau)}] = \sum_{t=1}^G Q_t = \sum_{t=1}^G \left(-(M+L)\log(\pi)-\log|\Sigma| - \right. \\ \left. (x_{o,t}-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(x_{o,t}-\mu_{X_{o,t}|Y_t})  -  tr([\Sigma_{Y_t}^{-1}]\Sigma_{Y_t|X_{o,t}}) - (\mu_{Y_t|X_{o,t}}-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t})\right)
\end{gathered}
\end{equation}
Как было сказано ранее, первые два слагаемые, составляющие $Q_t$ не зависят от $\theta$, а значит задача о поиске $\argmax_{\theta} E[\log P(X_o, \, Y|\theta^{(\tau)})|X_o, \theta^{(\tau)}] $ сводится к поиску
\begin{equation}
\begin{gathered}
\argmin_{\theta}  \sum_{t=1}^G \left((x_{o,t}-\mu_{X_{o,t}|Y_t})^H\Sigma_{X_{o,t}|Y_t}^{-1}(x_{o,t}-\mu_{X_{o,t}|Y_t}) +  tr([\Sigma_{Y_t}^{-1}]\Sigma_{Y_t|X_{o,t}}) \right. \\ \left. +  (\mu_{Y_t|X_{o,t}}-\mu_{Y_t})^H\Sigma_{Y_t}^{-1}(\mu_{Y_t|X_{o,t}}-\mu_{Y_t})\right).
\end{gathered}
\end{equation}
Учтем, что $\mu_{Y_t} = O_{(M+L_2) \times 1}$, в рамках задачи $y_t$ -- скрытая переменная, она оценивается так: $\hat{y}_t = \mu_{Y_t|X_{o,t}}$.
\begin{equation}
\left\{ \begin{gathered} 
\Sigma_{X_{o,t}|Y_t} = \Sigma_{X_{o,t}}-\Sigma_{X_{o,t}|Y_t}\Sigma_{Y_t}^{-1}\Sigma_{Y_t|X_{o,t}} \\
\mu_{X_{o,t}|Y_t} = \mu_{X_{o,t}} + \Sigma_{X_{o,t}|Y_t}\Sigma_{Y_t}^{-1}\cdot(y_o-\mu_{Y_t}),
\end{gathered} \right.
\end{equation}
\end{document}
